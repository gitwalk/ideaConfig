<application>
  <component name="AppStorage">
    <histories>
      <item value="escape Name Pattern" />
      <item value="Return the metadata for the specified table handle" />
      <item value="Information Schema Metadata" />
      <item value="catalog Name" />
      <item value="Qualified Table Prefix" />
      <item value="calculate Prefixes With Table Name" />
      <item value="HARD_AFFINITY: Split is NOT remotely accessible and has to be on specific nodes" />
      <item value="Indicate the node affinity of a Split" />
      <item value="catalog, schema and table names are reported by the remote database" />
      <item value="eventually add some notion of statistic reliability // Skipping for now as there hard to compute it properly and so far we do not have // usecase for that" />
      <item value="Estimate" />
      <item value="extra Credentials" />
      <item value="identifier Quote" />
      <item value="Prepared Statement" />
      <item value="with Required Subfields" />
      <item value="Pruning must preserve the type of the values and support unmodified access" />
      <item value="A logical plan node with single child" />
      <item value="Generic Leaf" />
      <item value="Generic" />
      <item value="Untyped Expression" />
      <item value="Defaults to the class name. * Note that we remove the &quot;Exec&quot; suffix for physical operators here" />
      <item value="Private" />
      <item value="PREDICATE" />
      <item value="present" />
      <item value="Returns an unmodifiable view of the underlying map's key set" />
      <item value="cardinality" />
      <item value="Spark configuration used to register Spline listener for codeless init." />
      <item value="An example job where no explicit Spline code was used to initialize Spline. Only Spark configuration was used" />
      <item value="The class must have a constructor with a single parameter of type {org.apache.commons.configuration.Configuration}" />
      <item value="Required for {HttpLineageDispatcher}. Base URL of the Spline Producer REST API endpoint" />
      <item value="Verify that the table does not already exist // dumpTable is only used to check the conflict for non-temporary tables" />
      <item value="With usejavacp=true, the Scala interpreter looks for jars under System Classpath. But it // doesn't look for jars added to MutableURLClassLoader. Thus extra jars are not visible to // the interpreter. SparkContext can use them via JVM ClassLoaders but users cannot import // them using Scala import statement." />
      <item value="then &quot;import com.databricks.spark.csv._&quot; in the interpreter, it will throw an error." />
      <item value="For instance: If we import a package using SparkConf:" />
      <item value="* Utility trait for classes that want to log data. Creates a SLF4J logger for the class and allows * logging messages at different levels using methods that only evaluate parameters lazily if the * log level is enabled." />
      <item value="SQL Interpreter" />
      <item value="Sets the Spark master URL to connect to, such as &quot;local&quot; to run locally, &quot;local[4]&quot; to * run locally with 4 cores, or &quot;spark://master:7077&quot; to run on a Spark standalone cluster." />
      <item value="Jdbc Identity" />
      <item value="schedule Drivers For Driver Group Life Cycle" />
      <item value="driver Runner Factories With Split Life Cycle" />
      <item value="Check Task Completion On Buffer Finish" />
      <item value="Pre-register Lifespans for ungrouped partitioned drivers in case they end up get no splits." />
      <item value="don't register the task if it is already completed (most likely failed during planning above)" />
      <item value="build the stage execution objects (this doesn't schedule execution)" />
      <item value="forget about this query if the query manager is no longer tracking it" />
      <item value="snapshot the queries before checking states to avoid registration race" />
      <item value="Sql Parser" />
      <item value="Drive index lookup to produce the output (landing in indexSnapshotBuilder)" />
      <item value="benchmark" />
      <item value="constant Blocks" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="948" />
        <entry key="ENGLISH" value="949" />
        <entry key="DANISH" value="2" />
        <entry key="GERMAN" value="1" />
        <entry key="FRENCH" value="3" />
        <entry key="FILIPINO" value="1" />
        <entry key="DUTCH" value="6" />
        <entry key="KURDISH" value="1" />
        <entry key="LATIN" value="1" />
        <entry key="ROMANIAN" value="1" />
        <entry key="NORWEGIAN" value="1" />
        <entry key="SWEDISH" value="2" />
        <entry key="ITALIAN" value="3" />
        <entry key="VIETNAMESE" value="1" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
  </component>
</application>