<application>
  <component name="AppStorage">
    <histories>
      <item value="position" />
      <item value="location" />
      <item value="change the location of position alias process here" />
      <item value="Resolved" />
      <item value="Generate" />
      <item value="Generate Resolved Parse tree from syntax tree" />
      <item value="Do semantic analysis and plan generation" />
      <item value="// Record current valid txn list that will be used throughout the query // compilation and processing. We only do this if 1) a transaction // was already opened and 2) the list has not been recorded yet, // e.g., by an explicit open transaction command." />
      <item value="Determines transaction type based on query AST" />
      <item value="also sets the hive operation in query state" />
      <item value="SemanticAnalyzer finds are in use" />
      <item value="clear CurrentFunctionsInUse set, to capture new set of functions // that SemanticAnalyzer finds are in use" />
      <item value="Enumerate numLevels of ancestors by putting them in the stack and dispatch * the current node. * * @param nd current operator in the ancestor tree * @param level how many level of ancestors included in the stack * @param stack operator stack * @throws SemanticException" />
      <item value="walk" />
      <item value="// We did not create the table before moving the data files for a non-partitioned table i.e // we used load file instead of load table (see SemanticAnalyzer#getFileSinkPlan() for // more details). Thus could not add a write notification required for a transactional // table. Do that here, after we have created the table. Since this is a newly created // table, listing all the files in the directory and listing only the ones corresponding to // the given id doesn't have much difference." />
      <item value="Any changes you make to this file will be ignored by Hive" />
      <item value="This file is auto generated for documentation purposes ONLY" />
      <item value="Comma-separated list of post-execution hooks to be invoked for each statement. A post-execution hook is specified as the name of a Java class which implements the org.apache.hadoop.hive.ql.hooks.ExecuteWithHookContext interface." />
      <item value="Internal" />
      <item value="Since we're reusing the compiled plan, we need to update its start time for current run" />
      <item value="the reason that we set the txn manager for the cxt here is because each // query has its own ctx object. The txn mgr is shared across the // same instance of Driver, which can run multiple queries." />
      <item value="use the specified database if specified" />
      <item value="Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once {@link #tryAcquire}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquire} until success. This method can be used * to implement method {@link Lock#lock}." />
      <item value="acquire Queued" />
      <item value="Eagerly cache singletons to be able to resolve circular references" />
      <item value="This class contains the lineage context that is passed * while walking the operator tree in Lineage. The context * contains the LineageInfo structure that is passed to the * pre-execution hooks." />
      <item value="Indicates that the column is derived from the output * of a user script through a TRANSFORM, MAP or REDUCE syntax * or from the output of a PTF chain execution." />
      <item value="Indicates that the column is derived from a UDF, UDAF, UDTF or * set operations like union on columns on other tables * e.g. T2.c1 = T1.c1 + T3.c1." />
      <item value="Indicates that the column is derived from another table column * with no transformations e.g. T2.c1 = T1.c1." />
      <item value="Gets the new dependency type by comparing the old dependency type and the * current dependency type. The current dependency type is the dependency imposed * by the current expression. Typically the dependency type is computed using * the following rules: * SCRIPT - In case anywhere in the lineage tree there was a script operator, otherwise * EXPRESSION - In case anywhere in the lineage tree a union, * udf, udaf or udtf was done, otherwise * SIMPLE - This captures direct column copies." />
      <item value="The parse context that is used to get table metadata information" />
      <item value="A map from a final select operator id to the select operator * and the corresponding target table in case an insert into query." />
      <item value="A map from operator to the conditions strings." />
      <item value="Put the dependency in the map" />
      <item value="Processor for TableScan Operator. This actually creates the base column mappings." />
      <item value="The operator whose dependency is being inserted." />
      <item value="Puts the dependency for an operator, columninfo tuple." />
      <item value="Processor for Script and UDTF Operators." />
      <item value="list of map join operators with no reducer" />
      <item value="list of destination files being loaded" />
      <item value="list of destination tables being loaded" />
      <item value="map from table scan operator to partition pruner" />
      <item value="Make sure the basic query properties are initialized" />
      <item value="Parse Context: The current parse context. This is passed to the optimizer * which then transforms the operator tree using the parse context. All the * optimizations are performed sequentially and then the new parse context * populated. Note that since the parse context contains the operator tree, it * can be easily retrieved by the next optimization step or finally for task * generation after the plan has been completely optimized." />
      <item value="Analyze the rewritten statement" />
      <item value="So, when expanding the definition of v while analyzing the top-level query, * we tag each ASTNode with a reference to an ASTNodeOrign describing v and its * usage within the query." />
      <item value="init Parse Ctx" />
      <item value="Create a clone of the parse context" />
      <item value="Take all the driver run hooks and post-execute them." />
      <item value="// for canceling the query (should be bound to session?)" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="207" />
        <entry key="ENGLISH" value="208" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
  </component>
</application>