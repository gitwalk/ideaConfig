<application>
  <component name="AppStorage">
    <histories>
      <item value="here" />
      <item value="Retrieve information about cache usage for the query." />
      <item value="Whether any error occurred during query compilation. Used for query lifetime hook" />
      <item value="do the authorization check" />
      <item value="Initialize the transaction manager. This must be done before analyze is called" />
      <item value="save some info for webUI for use after plan is freed" />
      <item value="command should be redacted to avoid to logging sensitive data" />
      <item value="This enables substitution using syntax like ${var} ${system:var} and ${env:var}." />
      <item value="// Transaction manager used for the query. This will be set at compile time based on // either initTxnMgr or from the SessionState, in that order." />
      <item value="Resets taskID counter if true" />
      <item value="deferClose indicates if the close/destroy should be deferred when the process has been // interrupted, it should be set to true if the compile is called within another method like // runInternal, which defers the close to the called in that method." />
      <item value="sql" />
      <item value="take a look to see if it is escaped" />
      <item value="Whether to include the current database in the Hive prompt" />
      <item value="Options Processor" />
      <item value="Operation processor of the CLI invocation" />
      <item value="materialized" />
      <item value="to" />
      <item value="Command line prompt configuration value. Other hiveconf can be used in this configuration value. \n&quot; + &quot;Variable substitution will only be invoked at the Hive CLI startup" />
      <item value="default" />
      <item value="prompt" />
      <item value="// Remember all threads that were running at the time we started line processing. // Hook up the custom Ctrl+C handler while processing this line" />
      <item value="hive Variable Source" />
      <item value="Compile a new query, but potentially reset taskID counter. Not resetting task counter * is useful for generating re-entrant QL queries." />
      <item value="/*It's imperative that {@code acquireLocks()} is called for all commands so that HiveTxnManager can transition its state machine correctly*/" />
      <item value="the sinks and DDL cannot coexist at this time; but if they could we would // need to make sure we don't get two write IDs for the same table" />
      <item value="it's possible to have &gt; 1 FileSink writing to the same table/partition * e.g. Merge stmt, multi-insert stmt when mixing DP and SP writes * Insert ... Select ... Union All Select ... using * {@link org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator#UNION_SUDBIR_PREFIX} */" />
      <item value="//sorting makes tests easier to write since file names and ROW__IDs depend on statementId //so this makes (file name -&gt; data) mapping stable" />
      <item value="Set the table write id in all of the acid file sinks" />
      <item value="Acquire read and write locks needed by the statement. The list of objects to be locked are * obtained from the inputs and outputs populated by the compiler. Locking strategy depends on * HiveTxnManager and HiveLockManager configured" />
      <item value="the sinks and DDL cannot coexist at this time; but if they could we would // need to make sure we don't get two write IDs for the same table." />
      <item value="does not add back up task here, because back up task should be the same // type of the original task" />
      <item value="require" />
      <item value="Lock operations themselves don't require the lock." />
      <item value="Concurrency mode is disabled, not creating a lock manager" />
      <item value="Assumes the query has already been compiled" />
      <item value="the release here will do nothing because there is no lock" />
      <item value="since set autocommit starts an implicit txn, close it" />
      <item value="Valid" />
      <item value="Lock acquisition should be moved before analyze, this is a bit hackish." />
      <item value="Currently, we acquire a snapshot, we compile the query wrt that snapshot, // and then, we acquire locks. If snapshot is still valid, we continue as usual. // But if snapshot is not valid, we recompile the query." />
      <item value="Snapshot was outdated when locks were acquired, hence regenerate context, // txn list and retry" />
      <item value="Checks whether txn list has been invalidated while planning the query. // This would happen if query requires exclusive/semi-shared lock, and there // has been a committed transaction on the table over which the lock is // required." />
      <item value="Trigger query hooks after query completes its execution." />
      <item value="// compile and execute can get called from different threads in case of HS2 // so clear timing in this thread's Hive object before proceeding." />
      <item value="// Snapshot was outdated when locks were acquired, hence regenerate context, // txn list and retry" />
      <item value="Since we're reusing the compiled plan, we need to update its start time for current run" />
      <item value="// deferClose indicates if the close/destroy should be deferred when the process has been // interrupted, it should be set to true if the compile is called within another method like // runInternal, which defers the close to the called in that method." />
      <item value="compile internal will automatically reset the perf logger" />
      <item value="Command Processor Response" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="366" />
        <entry key="ENGLISH" value="367" />
        <entry key="DUTCH" value="2" />
      </map>
    </option>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
  </component>
</application>